{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNVq2IE395hQoNnUJlIjc6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haru4me/deep-rl-cource/blob/master/notebooks/unit7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI vs AI: Soccer Team Game"
      ],
      "metadata": {
        "id": "W9uKVeaqFzSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Install MLAgents and download the correct executable"
      ],
      "metadata": {
        "id": "qJ2QfpVLF5r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Unity-Technologies/ml-agents/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Gi-QxEGQPQ",
        "outputId": "e3603c7c-c5b2-47ab-f7ff-1dd19bc96a8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-agents'...\n",
            "remote: Enumerating objects: 92575, done.\u001b[K\n",
            "remote: Counting objects: 100% (508/508), done.\u001b[K\n",
            "remote: Compressing objects: 100% (286/286), done.\u001b[K\n",
            "remote: Total 92575 (delta 203), reused 416 (delta 164), pack-reused 92067\u001b[K\n",
            "Receiving objects: 100% (92575/92575), 2.89 GiB | 13.01 MiB/s, done.\n",
            "Resolving deltas: 100% (67368/67368), done.\n",
            "Updating files: 100% (2215/2215), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ml-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hasWABG8m312",
        "outputId": "e3292e58-a609-4305-b9c2-386ea0e743ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ml-agents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -e ./ml-agents-envs\n",
        "!pip install -e ./ml-agents"
      ],
      "metadata": {
        "id": "GO45Djpem50-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./training-envs-executables"
      ],
      "metadata": {
        "id": "kz69RzeZJ7mO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качаем агента из [drive](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view) и закидываем в папку"
      ],
      "metadata": {
        "id": "kGAZ-yGwlovb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip -d ./training-envs-executables ./training-envs-executables/SoccerTwos.zip"
      ],
      "metadata": {
        "id": "crBHTRDEaSBN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Understand the environment"
      ],
      "metadata": {
        "id": "zrrK4nAAGgcP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZWFps6JHGbvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Understand MA-POCA"
      ],
      "metadata": {
        "id": "S6dd7hOjGjOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doERx9qaFpqS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define the config file\n",
        "\n",
        "The config file we’re going to use here is in ./config/poca/SoccerTwos.yaml. It looks like this:\n",
        "\n",
        "```yaml\n",
        "behaviors:\n",
        "  SoccerTwos:\n",
        "    trainer_type: poca\n",
        "    hyperparameters:\n",
        "      batch_size: 2048\n",
        "      buffer_size: 20480\n",
        "      learning_rate: 0.0003\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "      learning_rate_schedule: constant\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 512\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "    keep_checkpoints: 5\n",
        "    max_steps: 5000000\n",
        "    time_horizon: 1000\n",
        "    summary_freq: 10000\n",
        "    self_play:\n",
        "      save_steps: 50000\n",
        "      team_change: 200000\n",
        "      swap_steps: 2000\n",
        "      window: 10\n",
        "      play_against_latest_model_ratio: 0.5\n",
        "      initial_elo: 1200.0\n",
        "```"
      ],
      "metadata": {
        "id": "YeapzoxJGmwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Start the training"
      ],
      "metadata": {
        "id": "6J54HZg8Gp3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 755 ./training-envs-executables/SoccerTwos/SoccerTwos.x86_64"
      ],
      "metadata": {
        "id": "ZIR8OuRvms0o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn ./config/poca/SoccerTwos.yaml --env=./training-envs-executables/SoccerTwos/SoccerTwos.x86_64 --run-id=\"SoccerTwos\" --no-graphics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa-OH4pUGrKX",
        "outputId": "15f0f003-29a7-408e-a651-6b8b531753b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2024-06-03 19:56:31.156420: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-03 19:56:31.156479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-03 19:56:31.157721: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-03 19:56:31.164615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-03 19:56:32.622889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.1.0.dev0,\n",
            "  ml-agents-envs: 1.1.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.3.0+cu121\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SoccerTwos?team=1\n",
            "[INFO] Connected new brain: SoccerTwos?team=0\n",
            "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
            "\ttrainer_type:\tpoca\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t2048\n",
            "\t  buffer_size:\t20480\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  learning_rate_schedule:\tconstant\n",
            "\t  beta_schedule:\tconstant\n",
            "\t  epsilon_schedule:\tconstant\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t50000000\n",
            "\ttime_horizon:\t1000\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\t\n",
            "\t  save_steps:\t50000\n",
            "\t  team_change:\t200000\n",
            "\t  swap_steps:\t2000\n",
            "\t  window:\t10\n",
            "\t  play_against_latest_model_ratio:\t0.5\n",
            "\t  initial_elo:\t1200.0\n",
            "\tbehavioral_cloning:\tNone\n",
            "/content/ml-agents/ml-agents/mlagents/trainers/torch_entities/utils.py:289: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3675.)\n",
            "  torch.nn.functional.one_hot(_act.T, action_size[i]).float()\n",
            "[INFO] SoccerTwos. Step: 10000. Time Elapsed: 32.501 s. Mean Reward: 0.000. Mean Group Reward: 0.234. Training. ELO: 1201.246.\n",
            "[INFO] SoccerTwos. Step: 20000. Time Elapsed: 60.453 s. Mean Reward: 0.000. Mean Group Reward: -0.308. Training. ELO: 1201.612.\n",
            "[INFO] SoccerTwos. Step: 30000. Time Elapsed: 76.850 s. Mean Reward: 0.000. Mean Group Reward: 0.272. Training. ELO: 1200.981.\n",
            "[INFO] SoccerTwos. Step: 40000. Time Elapsed: 97.281 s. Mean Reward: 0.000. Mean Group Reward: -0.102. Training. ELO: 1200.103.\n",
            "[INFO] SoccerTwos. Step: 50000. Time Elapsed: 117.225 s. Mean Reward: 0.000. Mean Group Reward: -0.063. Training. ELO: 1199.729.\n",
            "[INFO] SoccerTwos. Step: 60000. Time Elapsed: 137.834 s. Mean Reward: 0.000. Mean Group Reward: -0.121. Training. ELO: 1200.337.\n",
            "[INFO] SoccerTwos. Step: 70000. Time Elapsed: 162.307 s. Mean Reward: 0.000. Mean Group Reward: -0.333. Training. ELO: 1200.108.\n",
            "[INFO] SoccerTwos. Step: 80000. Time Elapsed: 185.197 s. Mean Reward: 0.000. Mean Group Reward: 0.131. Training. ELO: 1199.983.\n",
            "[INFO] SoccerTwos. Step: 90000. Time Elapsed: 192.242 s. Mean Reward: 0.000. Mean Group Reward: 0.035. Training. ELO: 1199.983.\n",
            "[INFO] SoccerTwos. Step: 100000. Time Elapsed: 221.085 s. Mean Reward: 0.000. Mean Group Reward: 0.030. Training. ELO: 1200.647.\n",
            "[INFO] SoccerTwos. Step: 110000. Time Elapsed: 235.825 s. Mean Reward: 0.000. Mean Group Reward: -0.239. Training. ELO: 1199.728.\n",
            "[INFO] SoccerTwos. Step: 120000. Time Elapsed: 266.362 s. Mean Reward: 0.000. Mean Group Reward: 0.201. Training. ELO: 1200.478.\n",
            "[INFO] SoccerTwos. Step: 130000. Time Elapsed: 278.203 s. Mean Reward: 0.000. Mean Group Reward: 0.044. Training. ELO: 1201.551.\n",
            "[INFO] SoccerTwos. Step: 140000. Time Elapsed: 309.717 s. Mean Reward: 0.000. Mean Group Reward: 0.096. Training. ELO: 1201.963.\n",
            "[INFO] SoccerTwos. Step: 150000. Time Elapsed: 332.905 s. Mean Reward: 0.000. Mean Group Reward: 0.151. Training. ELO: 1201.963.\n",
            "[INFO] SoccerTwos. Step: 160000. Time Elapsed: 349.224 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 170000. Time Elapsed: 368.355 s. Mean Reward: 0.000. Mean Group Reward: -0.156. Training. ELO: 1200.708.\n",
            "[INFO] SoccerTwos. Step: 180000. Time Elapsed: 390.620 s. Mean Reward: 0.000. Mean Group Reward: -0.250. Training. ELO: 1200.965.\n",
            "[INFO] SoccerTwos. Step: 190000. Time Elapsed: 412.403 s. Mean Reward: 0.000. Mean Group Reward: -0.221. Training. ELO: 1200.089.\n",
            "[INFO] SoccerTwos. Step: 200000. Time Elapsed: 438.393 s. Mean Reward: 0.000. Mean Group Reward: 0.115. Training. ELO: 1199.964.\n",
            "[INFO] SoccerTwos. Step: 210000. Time Elapsed: 466.663 s. Mean Reward: 0.000. Mean Group Reward: 0.003. Training. ELO: 1200.298.\n",
            "[INFO] SoccerTwos. Step: 220000. Time Elapsed: 483.000 s. Mean Reward: 0.000. Mean Group Reward: 0.265. Training. ELO: 1200.213.\n",
            "[INFO] SoccerTwos. Step: 230000. Time Elapsed: 509.069 s. Mean Reward: 0.000. Mean Group Reward: -0.056. Training. ELO: 1200.585.\n",
            "[INFO] SoccerTwos. Step: 240000. Time Elapsed: 525.053 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 250000. Time Elapsed: 545.376 s. Mean Reward: 0.000. Mean Group Reward: 0.122. Training. ELO: 1199.961.\n",
            "[INFO] SoccerTwos. Step: 260000. Time Elapsed: 568.232 s. Mean Reward: 0.000. Mean Group Reward: -0.358. Training. ELO: 1199.840.\n",
            "[INFO] SoccerTwos. Step: 270000. Time Elapsed: 590.468 s. Mean Reward: 0.000. Mean Group Reward: 0.021. Training. ELO: 1199.727.\n",
            "[INFO] SoccerTwos. Step: 280000. Time Elapsed: 607.595 s. Mean Reward: 0.000. Mean Group Reward: -0.147. Training. ELO: 1200.315.\n",
            "[INFO] SoccerTwos. Step: 290000. Time Elapsed: 630.365 s. Mean Reward: 0.000. Mean Group Reward: -0.121. Training. ELO: 1199.987.\n",
            "[INFO] SoccerTwos. Step: 300000. Time Elapsed: 650.162 s. Mean Reward: 0.000. Mean Group Reward: 0.014. Training. ELO: 1199.409.\n",
            "[INFO] SoccerTwos. Step: 310000. Time Elapsed: 670.000 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1198.997.\n",
            "[INFO] SoccerTwos. Step: 320000. Time Elapsed: 692.431 s. Mean Reward: 0.000. Mean Group Reward: -0.111. Training. ELO: 1198.997.\n",
            "[INFO] SoccerTwos. Step: 330000. Time Elapsed: 717.637 s. Mean Reward: 0.000. Mean Group Reward: -0.009. Training. ELO: 1198.997.\n",
            "[INFO] SoccerTwos. Step: 340000. Time Elapsed: 733.992 s. Mean Reward: 0.000. Mean Group Reward: 0.069. Training. ELO: 1200.244.\n",
            "[INFO] SoccerTwos. Step: 350000. Time Elapsed: 756.048 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
            "[INFO] SoccerTwos. Step: 360000. Time Elapsed: 782.280 s. Mean Reward: 0.000. Mean Group Reward: 0.121. Training. ELO: 1202.224.\n",
            "[INFO] SoccerTwos. Step: 370000. Time Elapsed: 800.284 s. Mean Reward: 0.000. Mean Group Reward: 0.279. Training. ELO: 1202.963.\n",
            "[INFO] SoccerTwos. Step: 380000. Time Elapsed: 821.055 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1202.963.\n",
            "[INFO] SoccerTwos. Step: 390000. Time Elapsed: 839.223 s. Mean Reward: 0.000. Mean Group Reward: 0.195. Training. ELO: 1204.197.\n",
            "[INFO] SoccerTwos. Step: 400000. Time Elapsed: 864.938 s. Mean Reward: 0.000. Mean Group Reward: -0.013. Training. ELO: 1204.819.\n",
            "[INFO] SoccerTwos. Step: 410000. Time Elapsed: 898.068 s. Mean Reward: 0.000. Mean Group Reward: 0.178. Training. ELO: 1206.866.\n",
            "[INFO] SoccerTwos. Step: 420000. Time Elapsed: 917.455 s. Mean Reward: 0.000. Mean Group Reward: -0.145. Training. ELO: 1209.098.\n",
            "[INFO] SoccerTwos. Step: 430000. Time Elapsed: 938.708 s. Mean Reward: 0.000. Mean Group Reward: 0.142. Training. ELO: 1208.734.\n",
            "[INFO] SoccerTwos. Step: 440000. Time Elapsed: 955.425 s. Mean Reward: 0.000. Mean Group Reward: 0.446. Training. ELO: 1210.325.\n",
            "[INFO] SoccerTwos. Step: 450000. Time Elapsed: 978.704 s. Mean Reward: 0.000. Mean Group Reward: -0.052. Training. ELO: 1210.389.\n",
            "[INFO] SoccerTwos. Step: 460000. Time Elapsed: 995.361 s. Mean Reward: 0.000. Mean Group Reward: 0.276. Training. ELO: 1210.771.\n",
            "[INFO] SoccerTwos. Step: 470000. Time Elapsed: 1017.377 s. Mean Reward: 0.000. Mean Group Reward: 0.320. Training. ELO: 1214.406.\n",
            "[INFO] SoccerTwos. Step: 480000. Time Elapsed: 1042.239 s. Mean Reward: 0.000. Mean Group Reward: 0.223. Training. ELO: 1218.401.\n",
            "[INFO] SoccerTwos. Step: 490000. Time Elapsed: 1062.814 s. Mean Reward: 0.000. Mean Group Reward: -0.588. Training. ELO: 1218.921.\n",
            "[INFO] SoccerTwos. Step: 500000. Time Elapsed: 1084.797 s. Mean Reward: 0.000. Mean Group Reward: -0.212. Training. ELO: 1218.997.\n",
            "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-499398.onnx\n",
            "[INFO] SoccerTwos. Step: 510000. Time Elapsed: 1112.447 s. Mean Reward: 0.000. Mean Group Reward: 0.091. Training. ELO: 1218.546.\n",
            "[INFO] SoccerTwos. Step: 520000. Time Elapsed: 1122.887 s. Mean Reward: 0.000. Mean Group Reward: -0.164. Training. ELO: 1218.689.\n",
            "[INFO] SoccerTwos. Step: 530000. Time Elapsed: 1148.778 s. Mean Reward: 0.000. Mean Group Reward: -0.184. Training. ELO: 1217.925.\n",
            "[INFO] SoccerTwos. Step: 540000. Time Elapsed: 1178.673 s. Mean Reward: 0.000. Mean Group Reward: 0.149. Training. ELO: 1219.649.\n",
            "[INFO] SoccerTwos. Step: 550000. Time Elapsed: 1187.341 s. Mean Reward: 0.000. Mean Group Reward: -0.201. Training. ELO: 1220.359.\n",
            "[INFO] SoccerTwos. Step: 560000. Time Elapsed: 1214.576 s. Mean Reward: 0.000. Mean Group Reward: 0.285. Training. ELO: 1221.804.\n",
            "[INFO] SoccerTwos. Step: 570000. Time Elapsed: 1226.289 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1222.287.\n",
            "[INFO] SoccerTwos. Step: 580000. Time Elapsed: 1250.978 s. Mean Reward: 0.000. Mean Group Reward: 0.125. Training. ELO: 1223.305.\n",
            "[INFO] SoccerTwos. Step: 590000. Time Elapsed: 1272.858 s. Mean Reward: 0.000. Mean Group Reward: 0.193. Training. ELO: 1224.870.\n",
            "[INFO] SoccerTwos. Step: 600000. Time Elapsed: 1293.726 s. Mean Reward: 0.000. Mean Group Reward: 0.413. Training. ELO: 1226.555.\n",
            "[INFO] SoccerTwos. Step: 610000. Time Elapsed: 1326.223 s. Mean Reward: 0.000. Mean Group Reward: -0.016. Training. ELO: 1229.449.\n",
            "[INFO] SoccerTwos. Step: 620000. Time Elapsed: 1349.284 s. Mean Reward: 0.000. Mean Group Reward: 0.079. Training. ELO: 1231.277.\n",
            "[INFO] SoccerTwos. Step: 630000. Time Elapsed: 1371.445 s. Mean Reward: 0.000. Mean Group Reward: 0.058. Training. ELO: 1232.136.\n",
            "[INFO] SoccerTwos. Step: 640000. Time Elapsed: 1393.929 s. Mean Reward: 0.000. Mean Group Reward: -0.336. Training. ELO: 1228.160.\n",
            "[INFO] SoccerTwos. Step: 650000. Time Elapsed: 1416.669 s. Mean Reward: 0.000. Mean Group Reward: 0.084. Training. ELO: 1228.228.\n",
            "[INFO] SoccerTwos. Step: 660000. Time Elapsed: 1437.929 s. Mean Reward: 0.000. Mean Group Reward: -0.380. Training. ELO: 1228.334.\n",
            "[INFO] SoccerTwos. Step: 670000. Time Elapsed: 1459.349 s. Mean Reward: 0.000. Mean Group Reward: -0.337. Training. ELO: 1227.299.\n",
            "[INFO] SoccerTwos. Step: 680000. Time Elapsed: 1480.845 s. Mean Reward: 0.000. Mean Group Reward: 0.045. Training. ELO: 1228.388.\n",
            "[INFO] SoccerTwos. Step: 690000. Time Elapsed: 1505.964 s. Mean Reward: 0.000. Mean Group Reward: -0.084. Training. ELO: 1230.385.\n",
            "[INFO] SoccerTwos. Step: 700000. Time Elapsed: 1518.622 s. Mean Reward: 0.000. Mean Group Reward: 0.132. Training. ELO: 1230.396.\n",
            "[INFO] SoccerTwos. Step: 710000. Time Elapsed: 1540.351 s. Mean Reward: 0.000. Mean Group Reward: -0.129. Training. ELO: 1230.035.\n",
            "[INFO] SoccerTwos. Step: 720000. Time Elapsed: 1570.273 s. Mean Reward: 0.000. Mean Group Reward: 0.210. Training. ELO: 1231.991.\n",
            "[INFO] SoccerTwos. Step: 730000. Time Elapsed: 1579.769 s. Mean Reward: 0.000. Mean Group Reward: -0.018. Training. ELO: 1233.645.\n",
            "[INFO] SoccerTwos. Step: 740000. Time Elapsed: 1608.472 s. Mean Reward: 0.000. Mean Group Reward: 0.222. Training. ELO: 1234.980.\n",
            "[INFO] SoccerTwos. Step: 750000. Time Elapsed: 1630.434 s. Mean Reward: 0.000. Mean Group Reward: 0.241. Training. ELO: 1237.980.\n",
            "[INFO] SoccerTwos. Step: 760000. Time Elapsed: 1651.800 s. Mean Reward: 0.000. Mean Group Reward: 0.159. Training. ELO: 1238.139.\n",
            "[INFO] SoccerTwos. Step: 770000. Time Elapsed: 1667.510 s. Mean Reward: 0.000. Mean Group Reward: 0.358. Training. ELO: 1239.048.\n",
            "[INFO] SoccerTwos. Step: 780000. Time Elapsed: 1695.817 s. Mean Reward: 0.000. Mean Group Reward: 0.384. Training. ELO: 1241.532.\n",
            "[INFO] SoccerTwos. Step: 790000. Time Elapsed: 1707.990 s. Mean Reward: 0.000. Mean Group Reward: -0.626. Training. ELO: 1243.075.\n",
            "[INFO] SoccerTwos. Step: 800000. Time Elapsed: 1733.877 s. Mean Reward: 0.000. Mean Group Reward: -0.033. Training. ELO: 1245.722.\n",
            "[INFO] SoccerTwos. Step: 810000. Time Elapsed: 1766.193 s. Mean Reward: 0.000. Mean Group Reward: 0.201. Training. ELO: 1246.450.\n",
            "[INFO] SoccerTwos. Step: 820000. Time Elapsed: 1782.560 s. Mean Reward: 0.000. Mean Group Reward: 0.192. Training. ELO: 1249.798.\n",
            "[INFO] SoccerTwos. Step: 830000. Time Elapsed: 1805.357 s. Mean Reward: 0.000. Mean Group Reward: -0.216. Training. ELO: 1248.791.\n",
            "[INFO] SoccerTwos. Step: 840000. Time Elapsed: 1831.378 s. Mean Reward: 0.000. Mean Group Reward: -0.004. Training. ELO: 1251.145.\n",
            "[INFO] SoccerTwos. Step: 850000. Time Elapsed: 1847.359 s. Mean Reward: 0.000. Mean Group Reward: -0.005. Training. ELO: 1252.391.\n",
            "[INFO] SoccerTwos. Step: 860000. Time Elapsed: 1872.437 s. Mean Reward: 0.000. Mean Group Reward: -0.124. Training. ELO: 1253.309.\n",
            "[INFO] SoccerTwos. Step: 870000. Time Elapsed: 1892.805 s. Mean Reward: 0.000. Mean Group Reward: -0.145. Training. ELO: 1252.287.\n",
            "[INFO] SoccerTwos. Step: 880000. Time Elapsed: 1912.230 s. Mean Reward: 0.000. Mean Group Reward: 0.251. Training. ELO: 1253.793.\n",
            "[INFO] SoccerTwos. Step: 890000. Time Elapsed: 1934.345 s. Mean Reward: 0.000. Mean Group Reward: -0.079. Training. ELO: 1254.211.\n",
            "[INFO] SoccerTwos. Step: 900000. Time Elapsed: 1955.295 s. Mean Reward: 0.000. Mean Group Reward: -0.055. Training. ELO: 1251.897.\n",
            "[INFO] SoccerTwos. Step: 910000. Time Elapsed: 1974.900 s. Mean Reward: 0.000. Mean Group Reward: -0.139. Training. ELO: 1255.192.\n",
            "[INFO] SoccerTwos. Step: 920000. Time Elapsed: 1994.012 s. Mean Reward: 0.000. Mean Group Reward: -0.127. Training. ELO: 1257.039.\n",
            "[INFO] SoccerTwos. Step: 930000. Time Elapsed: 2017.028 s. Mean Reward: 0.000. Mean Group Reward: 0.101. Training. ELO: 1254.999.\n",
            "[INFO] SoccerTwos. Step: 940000. Time Elapsed: 2037.906 s. Mean Reward: 0.000. Mean Group Reward: 0.352. Training. ELO: 1262.244.\n",
            "[INFO] SoccerTwos. Step: 950000. Time Elapsed: 2066.030 s. Mean Reward: 0.000. Mean Group Reward: 0.273. Training. ELO: 1270.113.\n",
            "[INFO] SoccerTwos. Step: 960000. Time Elapsed: 2082.802 s. Mean Reward: 0.000. Mean Group Reward: 0.136. Training. ELO: 1273.214.\n",
            "[INFO] SoccerTwos. Step: 970000. Time Elapsed: 2108.118 s. Mean Reward: 0.000. Mean Group Reward: 0.172. Training. ELO: 1276.005.\n",
            "[INFO] SoccerTwos. Step: 980000. Time Elapsed: 2124.083 s. Mean Reward: 0.000. Mean Group Reward: 0.046. Training. ELO: 1282.316.\n",
            "[INFO] SoccerTwos. Step: 990000. Time Elapsed: 2148.388 s. Mean Reward: 0.000. Mean Group Reward: 0.338. Training. ELO: 1284.083.\n",
            "[INFO] SoccerTwos. Step: 1000000. Time Elapsed: 2169.019 s. Mean Reward: 0.000. Mean Group Reward: -0.065. Training. ELO: 1283.442.\n",
            "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-999992.onnx\n",
            "[INFO] SoccerTwos. Step: 1010000. Time Elapsed: 2199.674 s. Mean Reward: 0.000. Mean Group Reward: 0.021. Training. ELO: 1281.332.\n",
            "[INFO] SoccerTwos. Step: 1020000. Time Elapsed: 2218.683 s. Mean Reward: 0.000. Mean Group Reward: 0.202. Training. ELO: 1286.475.\n",
            "[INFO] SoccerTwos. Step: 1030000. Time Elapsed: 2245.800 s. Mean Reward: 0.000. Mean Group Reward: 0.117. Training. ELO: 1288.590.\n",
            "[INFO] SoccerTwos. Step: 1040000. Time Elapsed: 2267.613 s. Mean Reward: 0.000. Mean Group Reward: 0.190. Training. ELO: 1289.261.\n",
            "[INFO] SoccerTwos. Step: 1050000. Time Elapsed: 2290.756 s. Mean Reward: 0.000. Mean Group Reward: -0.262. Training. ELO: 1287.455.\n",
            "[INFO] SoccerTwos. Step: 1060000. Time Elapsed: 2306.759 s. Mean Reward: 0.000. Mean Group Reward: -0.042. Training. ELO: 1288.546.\n",
            "[INFO] SoccerTwos. Step: 1070000. Time Elapsed: 2333.517 s. Mean Reward: 0.000. Mean Group Reward: 0.181. Training. ELO: 1291.979.\n",
            "[INFO] SoccerTwos. Step: 1080000. Time Elapsed: 2353.752 s. Mean Reward: 0.000. Mean Group Reward: 0.220. Training. ELO: 1294.507.\n",
            "[INFO] SoccerTwos. Step: 1090000. Time Elapsed: 2374.971 s. Mean Reward: 0.000. Mean Group Reward: 0.292. Training. ELO: 1299.858.\n",
            "[INFO] SoccerTwos. Step: 1100000. Time Elapsed: 2395.117 s. Mean Reward: 0.000. Mean Group Reward: 0.391. Training. ELO: 1309.215.\n",
            "[INFO] SoccerTwos. Step: 1110000. Time Elapsed: 2417.471 s. Mean Reward: 0.000. Mean Group Reward: -0.293. Training. ELO: 1313.151.\n",
            "[INFO] SoccerTwos. Step: 1120000. Time Elapsed: 2438.912 s. Mean Reward: 0.000. Mean Group Reward: -0.249. Training. ELO: 1309.578.\n",
            "[INFO] SoccerTwos. Step: 1130000. Time Elapsed: 2457.525 s. Mean Reward: 0.000. Mean Group Reward: -0.248. Training. ELO: 1305.547.\n",
            "[INFO] SoccerTwos. Step: 1140000. Time Elapsed: 2487.971 s. Mean Reward: 0.000. Mean Group Reward: 0.054. Training. ELO: 1308.353.\n",
            "[INFO] SoccerTwos. Step: 1150000. Time Elapsed: 2506.649 s. Mean Reward: 0.000. Mean Group Reward: 0.217. Training. ELO: 1309.859.\n",
            "[INFO] SoccerTwos. Step: 1160000. Time Elapsed: 2530.873 s. Mean Reward: 0.000. Mean Group Reward: 0.076. Training. ELO: 1315.529.\n",
            "[INFO] SoccerTwos. Step: 1170000. Time Elapsed: 2551.628 s. Mean Reward: 0.000. Mean Group Reward: -0.025. Training. ELO: 1317.097.\n",
            "[INFO] SoccerTwos. Step: 1180000. Time Elapsed: 2574.370 s. Mean Reward: 0.000. Mean Group Reward: 0.023. Training. ELO: 1318.950.\n",
            "[INFO] SoccerTwos. Step: 1190000. Time Elapsed: 2593.792 s. Mean Reward: 0.000. Mean Group Reward: 0.321. Training. ELO: 1324.946.\n",
            "[INFO] SoccerTwos. Step: 1200000. Time Elapsed: 2617.555 s. Mean Reward: 0.000. Mean Group Reward: -0.010. Training. ELO: 1324.014.\n",
            "[INFO] SoccerTwos. Step: 1210000. Time Elapsed: 2638.766 s. Mean Reward: 0.000. Mean Group Reward: 0.070. Training. ELO: 1328.368.\n",
            "[INFO] SoccerTwos. Step: 1220000. Time Elapsed: 2664.532 s. Mean Reward: 0.000. Mean Group Reward: 0.011. Training. ELO: 1329.243.\n",
            "[INFO] SoccerTwos. Step: 1230000. Time Elapsed: 2685.387 s. Mean Reward: 0.000. Mean Group Reward: 0.106. Training. ELO: 1334.943.\n",
            "[INFO] SoccerTwos. Step: 1240000. Time Elapsed: 2709.242 s. Mean Reward: 0.000. Mean Group Reward: 0.328. Training. ELO: 1345.482.\n",
            "[INFO] Learning was interrupted. Please wait while the graph is generated.\n",
            "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-1248550.onnx\n",
            "[INFO] Copied results/SoccerTwos/SoccerTwos/SoccerTwos-1248550.onnx to results/SoccerTwos/SoccerTwos.onnx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Push the agent to the Hugging Face Hub"
      ],
      "metadata": {
        "id": "QBmjkX9EGs5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "u7KwGCe7Gtad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca7bb0d-8129-4660-ebc9-2330df7622ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf --run-id=\"SoccerTwos\" --local-dir=\"./results/SoccerTwos\" --repo-id=\"Haru4me/poca-SoccerTwos\" --commit-message=\"First Push\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn8ZAju0ne2-",
        "outputId": "6db064b1-a2ee-4e0c-d47f-fa68f0fee88b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] This function will create a model card and upload your SoccerTwos into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
            "[INFO] Pushing repo SoccerTwos to the Hugging Face Hub\n",
            "Upload 9 LFS files:   0% 0/9 [00:00<?, ?it/s]\n",
            "SoccerTwos.onnx:   0% 0.00/1.77M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:   0% 0.00/28.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.onnx:   0% 0.00/1.77M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.onnx:   0% 0.00/1.77M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:   0% 0.00/28.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.onnx:   1% 16.4k/1.77M [00:00<00:20, 85.2kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:   0% 16.4k/28.4M [00:00<06:07, 77.4kB/s]\u001b[A\u001b[A\u001b[A\n",
            "SoccerTwos.onnx:   1% 16.4k/1.77M [00:00<00:23, 73.2kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:   0% 16.4k/28.4M [00:00<06:53, 68.8kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.onnx:   1% 16.4k/1.77M [00:00<00:26, 66.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:   6% 1.67M/28.4M [00:00<00:04, 5.96MB/s]\u001b[A\u001b[A\u001b[A\n",
            "SoccerTwos.onnx:  94% 1.65M/1.77M [00:00<00:00, 5.17MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.onnx:  88% 1.56M/1.77M [00:00<00:00, 4.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:   6% 1.82M/28.4M [00:00<00:05, 5.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-999992.onnx: 100% 1.77M/1.77M [00:00<00:00, 2.79MB/s]\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  11% 3.03M/28.4M [00:00<00:06, 3.94MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:   0% 0.00/28.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:   9% 2.44M/28.4M [00:01<00:13, 1.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:   8% 2.23M/28.4M [00:00<00:01, 14.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  13% 3.82M/28.4M [00:01<00:08, 2.88MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  10% 2.82M/28.4M [00:01<00:11, 2.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  22% 6.28M/28.4M [00:01<00:03, 5.66MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  18% 5.11M/28.4M [00:01<00:04, 5.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  27% 7.77M/28.4M [00:01<00:02, 6.95MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  23% 6.47M/28.4M [00:01<00:03, 6.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  33% 9.50M/28.4M [00:01<00:02, 8.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  30% 8.60M/28.4M [00:01<00:02, 8.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-499398.onnx: 100% 1.77M/1.77M [00:01<00:00, 1.02MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  37% 10.4M/28.4M [00:01<00:01, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos.onnx: 100% 1.77M/1.77M [00:01<00:00, 947kB/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  45% 12.9M/28.4M [00:01<00:01, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  13% 3.65M/28.4M [00:01<00:08, 3.08MB/s]\u001b[A\u001b[A\n",
            "checkpoint.pt:   0% 0.00/28.4M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload 9 LFS files:  11% 1/9 [00:02<00:18,  2.26s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "events.out.tfevents.1717444595.54e6afaba2c5.3477.0:   0% 0.00/1.13M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "checkpoint.pt:  12% 3.34M/28.4M [00:00<00:00, 31.1MB/s]\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  25% 7.21M/28.4M [00:01<00:03, 6.36MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  31% 8.83M/28.4M [00:01<00:02, 7.89MB/s]\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  38% 10.8M/28.4M [00:01<00:01, 9.93MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  57% 16.3M/28.4M [00:02<00:01, 6.22MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  56% 16.0M/28.4M [00:02<00:01, 7.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  46% 13.2M/28.4M [00:01<00:01, 12.9MB/s]\u001b[A\u001b[A\n",
            "checkpoint.pt:  23% 6.46M/28.4M [00:00<00:01, 12.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  75% 21.3M/28.4M [00:02<00:00, 11.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  77% 21.8M/28.4M [00:02<00:00, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "checkpoint.pt:  29% 8.26M/28.4M [00:00<00:01, 11.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  87% 24.8M/28.4M [00:02<00:00, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  87% 24.7M/28.4M [00:02<00:00, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "checkpoint.pt:  34% 9.67M/28.4M [00:00<00:01, 10.1MB/s]\u001b[A\n",
            "checkpoint.pt:  38% 10.8M/28.4M [00:01<00:01, 8.98MB/s]\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  56% 16.0M/28.4M [00:02<00:01, 6.71MB/s]\u001b[A\u001b[A\n",
            "checkpoint.pt:  42% 11.9M/28.4M [00:01<00:02, 8.09MB/s]\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  74% 21.1M/28.4M [00:02<00:00, 11.9MB/s]\u001b[A\u001b[A\n",
            "checkpoint.pt:  47% 13.5M/28.4M [00:01<00:01, 9.34MB/s]\u001b[A\n",
            "checkpoint.pt:  53% 15.0M/28.4M [00:01<00:01, 10.4MB/s]\u001b[A\n",
            "\n",
            "events.out.tfevents.1717444595.54e6afaba2c5.3477.0: 100% 1.13M/1.13M [00:01<00:00, 819kB/s]\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-1248550.pt:  98% 28.0M/28.4M [00:03<00:00, 7.01MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos-499398.pt:  98% 27.9M/28.4M [00:03<00:00, 7.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SoccerTwos.onnx:   0% 0.00/1.77M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SoccerTwos-999992.pt:  96% 27.3M/28.4M [00:03<00:00, 8.13MB/s]\u001b[A\u001b[A\n",
            "checkpoint.pt:  57% 16.2M/28.4M [00:02<00:03, 4.03MB/s]\u001b[A\n",
            "SoccerTwos.onnx: 100% 1.77M/1.77M [00:00<00:00, 2.72MB/s]\n",
            "\n",
            "SoccerTwos-499398.pt: 100% 28.4M/28.4M [00:04<00:00, 5.87MB/s]\n",
            "SoccerTwos-1248550.pt: 100% 28.4M/28.4M [00:04<00:00, 5.86MB/s]\n",
            "\n",
            "SoccerTwos-999992.pt: 100% 28.4M/28.4M [00:04<00:00, 6.39MB/s]\n",
            "\n",
            "checkpoint.pt: 100% 28.4M/28.4M [00:04<00:00, 6.49MB/s]\n",
            "Upload 9 LFS files: 100% 9/9 [00:06<00:00,  1.30it/s]\n",
            "[INFO] Your model is pushed to the hub. You can view your model here: https://huggingface.co/Haru4me/poca-SoccerTwos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Verify that your model is ready for AI vs AI Challenge"
      ],
      "metadata": {
        "id": "EbjNPJQ9Gt2m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmWO4cqyGuKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Visualize some match in our demo"
      ],
      "metadata": {
        "id": "r3yba5n3Gudl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "asVycSkqGu9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}